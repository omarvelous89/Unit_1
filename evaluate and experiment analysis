1. The Sith Lords are concerned that their recruiting slogan, "Give In to Your Anger," isn't very effective. Darth Vader develops an alternative slogan, "Together We Can Rule the Galaxy." They compare the slogans on two groups of 50 captured droids each. In one group, Emperor Palpatine delivers the "Anger" slogan. In the other, Darth Vader presents the "Together" slogan. 20 droids convert to the Dark Side after hearing Palpatine's slogan, while only 5 droids convert after hearing Vader's. The Sith's data scientist concludes that "Anger" is a more effective slogan and should continue to be used.

Vader hasn't discounted the fact that he and Palpitine deliver different speeches to different groups. It's hard to disentangle Vader likeability(or lack of) from the likeability(or lack of) of the anger message. 

There is also a problem of sample choice. Captured droids (assuming they have free will similar to humans) won't give in to their war captors as a general rule. Those who do are the exeptions to the rule.

Sample size is also an issue. This is a galactic empire so a sample size of one demographic is hardly representative of all droids let alone the galaxy.

2. In the past, the Jedi have had difficulty with public relations. They send two envoys, Jar Jar Binks and Mace Windu, to four friendly and four unfriendly planets respectively, with the goal of promoting favorable feelings toward the Jedi. Upon their return, the envoys learn that Jar Jar was much more effective than Windu: Over 75% of the people surveyed said their attitudes had become more favorable after speaking with Jar Jar, while only 65% said their attitudes had become more favorable after speaking with Windu. This makes Windu angry, because he is sure that he had a better success rate than Jar Jar on every planet. The Jedi choose Jar Jar to be their representative in the future.

The two groups are very different but the Jedi have aggregated all their responses on who they spoke with. We expect friendly planets to respond well, but what we don't expect is hostile planets to do so. One task is then more valuable than the other and shouldn't be weighted equally. If Jar Jar has slightly better results with friendly planets but Mace Windu performs better with the unfriendly planets then I would weigh that as more valuable. It pays to look at are data separately sometimes.

Assuming one task was harder, it makes the ten percent difference in their subjective scores all the more insignificant but the Jedi have placed a large importance on the number value. This is an example of Surrogation Bias defined as "Losing sight of the strategic construct that a measure is intended to represent, and subsequently acting as though the measure is the construct of interest." The construct here is the diplomatic missions and their impact measured by the surveys. The survey result has been surrogated for the actual analysis.



3. A company with work sites in five different countries has sent you data on employee satisfaction rates for workers in Human Resources and workers in Information Technology. Most HR workers are concentrated in three of the countries, while IT workers are equally distributed across worksites. The company requests a report on satisfaction for each job type. You calculate average job satisfaction for HR and for IT and present the report.

Workers aren't spread out evenly in the company structure so there is a framing bias in how this data is presented as HR vs IT.

A Congruence Bias is also at play in that the company is only testing employee in one way and not testing other hypothesis. It's possible that information grouped by country will be more useful as it will contain information unique to that worksite that could be affecting employee satisfaction



4. When people install the Happy Days Fitness Tracker app, they are asked to "opt in" to a data collection scheme where their level of physical activity data is automatically sent to the company for product research purposes. During your interview with the company, they tell you that the app is very effective because after installing the app, the data show that people's activity levels rise steadily.

Some people who don't opt in may have positive results may not be taken into account. Those who don't opt-in may even have poor results that won't be taken into account when analyzing the app. 

Measuring success by activity level is also an issue. Different people use the app for different reasons and have different goals in how they use the app. Someone who uses it by adhering to a strict routine won't show an increased use over time because their use is constant but they are positive use case for the app. The choice of key metric here is narrow.

5. To prevent cheating, a teacher writes three versions of a test. She stacks the three versions together, first all copies of Version A, then all copies of Version B, then all copies of Version C. As students arrive for the exam, each student takes a test. When grading the test, the teacher finds that students who took Version B scored higher than students who took either Version A or Version C. She concludes from this that Version B is easier, and discards it.

The teacher didn't hand out her versions evenly but stacked them so her groups are potentially different sizes. If this is also the first time she has tried out this test, then she doesn't have enough data to conclude that version is definitely easier. The sample size just isn't large enough to take into account that different students have different test taking personalities and know different subsets of the information better. Repeat the experiment.




